{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Case-Study:-Create-a-Movie-Recommender\">Case Study: Create a Movie Recommender</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "\n",
    "### One of the first steps in any data science task is importing the necessary tools you will use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in /srv/conda/envs/notebook/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from scikit-surprise) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from scikit-surprise) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from scikit-surprise) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from scikit-surprise) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: If !pip install scikit-surprise doesn't work, please install using the anconda prompt by typing the following command\n",
    "      conda install -c conda-forge scikit-surprise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import  SVD, NormalPredictor, KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count   Dtype\n",
      "---  ------   --------------   -----\n",
      " 0   user_id  100000 non-null  int64\n",
      " 1   item_id  100000 non-null  int64\n",
      " 2   rating   100000 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.3 MB\n"
     ]
    }
   ],
   "source": [
    "col_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "data = pd.read_table('u.data', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "data = data.drop('timestamp', axis=1)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the dataset. How many ratings are in the dataset? How would you describe the distribution of ratings? Is there anything else we should observe? Make sure the histogram is visible in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>462.48475</td>\n",
       "      <td>425.530130</td>\n",
       "      <td>3.529860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>266.61442</td>\n",
       "      <td>330.798356</td>\n",
       "      <td>1.125674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>254.00000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>447.00000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>682.00000</td>\n",
       "      <td>631.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>943.00000</td>\n",
       "      <td>1682.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id        item_id         rating\n",
       "count  100000.00000  100000.000000  100000.000000\n",
       "mean      462.48475     425.530130       3.529860\n",
       "std       266.61442     330.798356       1.125674\n",
       "min         1.00000       1.000000       1.000000\n",
       "25%       254.00000     175.000000       3.000000\n",
       "50%       447.00000     322.000000       4.000000\n",
       "75%       682.00000     631.000000       4.000000\n",
       "max       943.00000    1682.000000       5.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0      196      242       3\n",
       "1      186      302       3\n",
       "2       22      377       1\n",
       "3      244       51       2\n",
       "4      166      346       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.rating.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data.user_id\n",
    "ratings_count = dict()\n",
    "for user in users:\n",
    "    if user in ratings_count:\n",
    "        ratings_count[user] += 1\n",
    "    else:\n",
    "        ratings_count[user] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_cutoff = 100\n",
    "remove_users = []\n",
    "for user, num_ratings in ratings_count.items():\n",
    "    if num_ratings < ratings_cutoff:\n",
    "        remove_users.append(user)\n",
    "data = data.loc[~data.user_id.isin(remove_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74522, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:** The dataset has 100000 rows and 3 columns highlighting user id, item id and rating. \n",
    "There are no nulls in the dataset.\n",
    "The rating ranges from 1 to 5, so there are five levels of rating. \n",
    "The data follows a left skewed distribution with the median of the rating at '4'. While Rating '3' is second highest in count with around 25% of the Rating dataset falling below it. \n",
    "The data is subset for further analysis and only those instances where count of ratings is greater than 100 is considered. Therefore , the updated dataset has the shape 74522 rows and 3 columns. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "\n",
    "We will be using cross validation a lot in this code in the training and evaluation of our models. This strategy builds upon the idea of a train-test split, which you should already be familiar with.\n",
    "\n",
    "Instead of doing 1 data split, though, we will do several of them. Each split of the data is called a fold. We let k denote the number of folds we use. k=5 is a common number to use.\n",
    "\n",
    "This image provides a visual explanation of how cross validation works.\n",
    "\n",
    "<img src =\"https://upload.wikimedia.org/wikipedia/commons/1/1c/K-fold_cross_validation_EN.jpg\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use \"cross_validate\" from surprise package to run the models as listed and check their respective RMSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coverting data in to surprise dataset\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(data[['user_id', 'item_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Random\n",
    "\n",
    "We want to first get a baseline value for our model. What better way to do that than with a random algorithm! Essentially, this first algorithm is not personalized to the desires of any users - we just assign them movie ratings based on the initial distribution of the data.\n",
    "\n",
    "See the Model 1: Random section of your notebook and follow the instructions to create a new model, train it on the data and evaluate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm predicting a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "model_random = NormalPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_using_normal_predictor = cross_validate(model_random, data,measures=['RMSE'],cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE for Test Set using NormalPredictor is  1.518584543200923\n"
     ]
    }
   ],
   "source": [
    "print('Average RMSE for Test Set using {} is '.format(model_random.__class__.__name__),model_using_normal_predictor['test_rmse'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: User-Based Collaborative Filtering\n",
    "\n",
    "Surely, we can do much better than guessing the movie ratings randomly! Our next model will use the user-user defined notion of similarity to implement collaborative filtering.\n",
    "\n",
    "See the Model 2: User-Based Collaborative Filtering section of your notebook and follow the instructions to create a new model, train it on the data and evaluate the RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " We will use KNNBasic and add parameter 'cosine' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_user_based = KNNBasic(sim_options ={'name':'cosine','user_base':True},verbose=False)\n",
    "model_using_KNNbasic_cos_user = cross_validate (model_user_based,data,measures=['RMSE'],cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE for Test Set using KNNBasic is  1.0171515331636156\n"
     ]
    }
   ],
   "source": [
    "print('Average RMSE for Test Set using {} is '.format(model_user_based.__class__.__name__),model_using_KNNbasic_cos_user['test_rmse'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Item-Based Collaborative Filtering\n",
    "\n",
    "Our next model will use the item-item defined notion of similarity to once again implement collaborative filtering.\n",
    "\n",
    "See the Model 3: Item-Based Collaborative Filtering section of your notebook and follow the instructions to create a new model, train it on the data and evaluate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_item_based = KNNBasic(sim_options ={'name':'cosine','user_base':False},verbose=False)\n",
    "model_using_KNNbasic_cos_item = cross_validate(model_item_based,data,measures=['RMSE'],cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE for Test Set using KNNBasic is  1.016597729769295\n"
     ]
    }
   ],
   "source": [
    "print('Average RMSE for Test Set using {} is '.format(model_item_based.__class__.__name__),model_using_KNNbasic_cos_item['test_rmse'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the results from the user-user and item-item models. How do they compare to each other? How do they compare to our original \"random\" model? Can you provide any intuition as to why the results came out the way they did?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "User-based Collaborative filtering with an average RMSE of 1.0113204732266379 and Item-based Collaborative filtering with an average RMSE of 1.0119979101202734 have nearly the same RMSE values while the 'Random' model's RMSE is the highest at 1.5172738007642097. Clearly, Collaborative filtering models have performed better than the random model.\n",
    "\n",
    "The Collaborative Models use the user-item-ratings data to find similarities among smaller subset of data and make predictions rather than just predicting a random rating based on the distribution of data. The underlying assumption that users with similar preferences will have similar preferences in the future as well helps us in predicting various choices that the user can possibly make using their preferences. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization\n",
    "\n",
    "Our final model for this case study will use the matrix factorization approach with the SVD algorithm to try to predict user’s movie ratings. Here, we try to determine some underlying mathematical structure in the user rating matrix, which can help us predict missing ratings in the future.\n",
    "\n",
    "See the Model 4: Matrix Factorization section of your notebook and follow the instructions to create a new model, train it on the data and evaluate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix factorisation using svd\n",
    "model_svd = SVD()\n",
    "model_using_svd = cross_validate(model_svd,data,measures=['RMSE'],cv=5, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE for Test Set using SVD is  0.9362776840758731\n"
     ]
    }
   ],
   "source": [
    "print('Average RMSE for Test Set using {} is '.format(model_svd.__class__.__name__),model_using_svd['test_rmse'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The matrix factorization model is different from the collaborative filtering models. Briefly describe this difference. Also, compare the RMSE again. Does it improve? Can you offer any reasoning as to why that might be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "Collaborative Filtering searches for neighbors based on similarity of product (example) preferences and recommend product that those neighbors bought/reviewed while Matrix factorization works by decomposing the user-item matrix into the product of two lower dimensionality rectangular matrices.\n",
    "\n",
    "RMSE for Matrix Factorization is slightly better than the Collaborative Filtering Models at 0.9233543891153753 .\n",
    "\n",
    "\n",
    "Matrix Factorization has lower RMSE due to the reason that it assumes  that  both product and users are present in some low dimensional space describing their properties and recommend a product based on its proximity to the user in the latent space. Implying it accounts for latent factors as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall @ k\n",
    "\n",
    "RMSE is not the only metric we can use here. We can also examine two fundamental measures, precision and recall. We also add a parameter k which is helpful in understanding problems with multiple rating outputs.\n",
    "\n",
    "See the Precision and Recall @ k section of your notebook and follow the instructions to compute various precision/recall values at various values of k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the precision and recall, for each of the 4 models, at k = 5 and 10. This is 2 x 2 x 4 = 16 numerical values. Do you note anything interesting about these values? Anything different from the RMSE values you computed above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function can be found on surprise documentation FAQs\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A basic cross-validation iterator.\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> k=5, model=NormalPredictor\n",
      "-----> Precision:  0.563\n",
      "-----> Recall:  0.322\n",
      "> k=5, model=KNNBasic\n",
      "-----> Precision:  0.735\n",
      "-----> Recall:  0.434\n",
      "> k=5, model=KNNBasic\n",
      "-----> Precision:  0.734\n",
      "-----> Recall:  0.435\n",
      "> k=5, model=SVD\n",
      "-----> Precision:  0.726\n",
      "-----> Recall:  0.412\n",
      "> k=10, model=NormalPredictor\n",
      "-----> Precision:  0.562\n",
      "-----> Recall:  0.408\n",
      "> k=10, model=KNNBasic\n",
      "-----> Precision:  0.703\n",
      "-----> Recall:  0.579\n",
      "> k=10, model=KNNBasic\n",
      "-----> Precision:  0.706\n",
      "-----> Recall:  0.576\n",
      "> k=10, model=SVD\n",
      "-----> Precision:  0.699\n",
      "-----> Recall:  0.54\n"
     ]
    }
   ],
   "source": [
    "# Make list of k values\n",
    "K = [5, 10]\n",
    "\n",
    "# Make list of models\n",
    "models = [model_random, model_user_based, model_item_based, model_svd]\n",
    "\n",
    "for k in K:\n",
    "    for model in models:\n",
    "        print('> k={}, model={}'.format(k,model.__class__.__name__))\n",
    "        p = []\n",
    "        r = []\n",
    "        for trainset, testset in kf.split(data):\n",
    "            model.fit(trainset)\n",
    "            predictions = model.test(testset, verbose=False)\n",
    "            precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=3.5)\n",
    "\n",
    "            # Precision and recall can then be averaged over all users\n",
    "            p.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "            r.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "        \n",
    "        print('-----> Precision: ', round(sum(p) / len(p), 3))\n",
    "        print('-----> Recall: ', round(sum(r) / len(r), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "Precision quantifies the number of positive class predictions that actually belong to the positive class.\n",
    "\n",
    "Recall quantifies the number of positive class predictions made out of all positive examples in the dataset.\n",
    "\n",
    "Random model performs the lowest with a precision value  of ~55.3% with k = 5 and ~55.6% with k = 10, while Collaborative filtering performs well with a precision value of ~80.9% with k = 5 and ~76.5% with k = 10.\n",
    "\n",
    "SVD has better RMSE but Collaborative Filtering using Item-Item or User-User have better Precision & Recall. SO SVD performs behind collaborative filtering with precision value of ~76.2% with k = 10 and ~80.3% with k = 5.\n",
    "\n",
    "RMSE values are used for Continuous d-type while Precision-Recall are calculated for categorical d-type using Confusion matrix. Thus cannot be compared directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-n Predictions\n",
    "\n",
    "Finally, we want to actually see what ratings the model predicts for our users. We can vary the amount of top movies we see per user by varying the value of n.\n",
    "\n",
    "See the Top-n Predictions section of your notebook and follow the instructions to compute rating predictions for some users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a href=https://surprise.readthedocs.io/en/stable/FAQ.html>documentation surprise</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: NormalPredictor, 196: [[ 222    5]\n",
      " [ 118    5]\n",
      " [ 546    5]\n",
      " [1137    5]\n",
      " [ 241    5]]\n"
     ]
    }
   ],
   "source": [
    "models = [model_random, model_user_based, model_item_based, model_svd]\n",
    "for model in models:\n",
    "    model.fit(trainset)\n",
    "    predictions = model.test(testset)\n",
    "    top_n = get_top_n(predictions, n=5)\n",
    "    # Print the first one\n",
    "    user = list(top_n.keys())[0]\n",
    "    print(f'model: {model.__class__.__name__}, {user}: {np.round(top_n[user],2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the top n predictions that you received make sense? What is the rating value (1-5) of these predictions? How could you use these predictions in the real-world if you were trying to build a generic content recommender system for a company?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "The predictions (n=5) for each model is computed and the predictions for One user for each model is printed out . Collaborative models (User-based & Item-based) have given exactly same recommendations as was expected considering their close RMSE values. \n",
    "\n",
    "The rating values for Random, User-based, Item-based and Matrix Factorization using SVD in fixed at 5. Recommender systems are used by E-commerce portals to recommend products to their customers. The products can be recommended based on the top overall sellers on a site, based on the demographics of the customer, or based on an analysis of the past buying behavior of the customer as a prediction for future buying behavior. Popular streaming sites like Netflix uses the collaborative filtering method in their recommendation system to predict new movies or shows that the user could possibly watch based on the user's preferences. With the booming e-commerce scenario in the next decade , recommendation systems would be extremely helpful to filter out products that the user may missed out on as well as to highlight products that would suit the preferences of the user thereby saving time and effort to browse through an endless lists of products . \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
